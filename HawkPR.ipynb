{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "tmOlloGI0bGZ"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Code for Hawks Process function tranlsated from matlab from chiangwe's HawkPR  repository"
      ],
      "metadata": {
        "id": "STQz73i9y3Yr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Python version"
      ],
      "metadata": {
        "id": "PTx8xNbm0fbe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Input variables*\n",
        "*(CSV Files)*\n",
        "\n",
        "Each has 2824 counties identified by an FIPS code\n",
        "1.   **Report** ;\n",
        "rows: 2824 x 6 (6 locations for cases);\n",
        "cols: 4 + 297 (dates) [15/02/20 - 07/12/20];\n",
        "records number of cases\n",
        "\n",
        "2. **Mobility**;\n",
        "rows: 2824 (counties);\n",
        "cols: 3 + 297 (dates);\n",
        "records amount of mobility\n",
        "\n",
        "3.   **Demography**;\n",
        "rows: 2824;\n",
        "cols: 9;\n",
        "records demographic identifiers of each county\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q98MDzys1kwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import time\n",
        "import random\n",
        "import scipy.stats as stats\n",
        "import scipy.sparse as sparse\n",
        "from scipy.stats import weibull_min, poisson\n",
        "from scipy.optimize import curve_fit\n",
        "from scipy.sparse import csc_matrix, eye\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.genmod.families import Poisson\n",
        "from sklearn.linear_model import PoissonRegressor\n",
        "from scipy import sparse\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjxFVHwr0ebs",
        "outputId": "0c54f8fe-6393-40eb-b75c-e5e8b44c740e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "code uses a weibull distribution to model inter infection times. the parameters are updated within the code according to the expectation maximization algorithm."
      ],
      "metadata": {
        "id": "nU4hELFWQbwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def HawkPR(InputPath_report, InputPath_mobility, InputPath_demography, Delta, Alpha, Beta, EMitr, DaysPred, SimTimes, OutputPath_mdl, OutputPath_pred):\n",
        "    warnings.filterwarnings('ignore')\n",
        "\n",
        "    # Read in parameters\n",
        "    if Alpha == '' and Beta == '':\n",
        "        print('No shape and scale parameter for Weibull distribution provided. Use MLE to infer alpha and beta ... ')\n",
        "        alphaScale_in = 0\n",
        "        betaShape_in = 0\n",
        "    else:\n",
        "        alphaScale_in = float(Alpha)\n",
        "        betaShape_in = float(Beta)\n",
        "\n",
        "    if Delta == '':\n",
        "        print('No shift parameter for mobility provided. It will set to zero ... ')\n",
        "        mobiShift_in = 0\n",
        "    else:\n",
        "        mobiShift_in = int(Delta)\n",
        "\n",
        "    # Read-in COVID data\n",
        "    NYT = pd.read_csv(InputPath_report)\n",
        "    NYT = NYT.iloc[:10,:-250]\n",
        "\n",
        "    # Read-in mobility\n",
        "    Mobi = pd.read_csv(InputPath_mobility)\n",
        "    Mobi = Mobi.iloc[:60,:-250]\n",
        "\n",
        "    # Read-in demographic\n",
        "    Demo = pd.read_csv(InputPath_demography)\n",
        "    Demo = Demo.iloc[:10,:]\n",
        "    Demo_val = Demo.iloc[:, 3:].values\n",
        "\n",
        "    # Data pre-processing\n",
        "    covid = NYT.iloc[:, 3:].values\n",
        "    covid = NYT.iloc[:, 3:].apply(pd.to_numeric, errors='coerce').values  # Convert to numeric, coerce errors to NaN\n",
        "    covid[np.isnan(covid)] = 0\n",
        "    covid = np.hstack([np.zeros((covid.shape[0], 1)), np.diff(covid, axis=1)])\n",
        "    covid[covid <= 0] = 0\n",
        "\n",
        "    # Pad to shift\n",
        "    mob_head = Mobi.iloc[:, :4]\n",
        "    mob_val = Mobi.iloc[:, 4:].values\n",
        "\n",
        "    for _ in range(mobiShift_in):\n",
        "        mob_val = np.hstack([np.mean(mob_val[:, :7], axis=1, keepdims=True), mob_val])\n",
        "\n",
        "    # Get Key and Date\n",
        "    NYT_Date_list = NYT.columns[3:]\n",
        "    NYT_Key_list = NYT.iloc[:, :3].values\n",
        "\n",
        "    Mobi_Type_list = Mobi.iloc[:6, 3].values\n",
        "    Mobi_Date_list = Mobi.columns[4:]\n",
        "    Mobi_Key_list = Mobi.iloc[::6, :3].values\n",
        "\n",
        "    Demo_Type_list = Demo.columns[3:]\n",
        "    Demo_Key_list = Demo.iloc[:, 0].values\n",
        "\n",
        "\n",
        "    n_cty, n_day = covid.shape\n",
        "    n_mobitype = mob_val.shape[0] // n_cty\n",
        "\n",
        "    print(f'There are {n_cty} counties, {n_mobitype} types of Mobility indices, and {n_day} days in the COVID reports.')\n",
        "\n",
        "    # Train & Test Split\n",
        "    n_tr = covid.shape[1] - DaysPred\n",
        "    mob_tr = mob_val[:, :n_tr]\n",
        "    mob_te = mob_val[:, n_tr:n_tr+DaysPred]\n",
        "\n",
        "    # Normalization\n",
        "    mob_tr_reshape = mob_tr.reshape(n_mobitype,-1).T\n",
        "    mob_te_reshape = mob_te.reshape(n_mobitype, -1).T\n",
        "\n",
        "    Demo_val_in = Demo_val\n",
        "    Demo_val_tr = np.tile(Demo_val_in, (n_tr, 1))\n",
        "    Demo_val_te = np.tile(Demo_val_in, (DaysPred, 1))\n",
        "\n",
        "    covid_tr = covid\n",
        "\n",
        "    Covar_tr = np.hstack([mob_tr_reshape, Demo_val_tr])\n",
        "    Covar_te = np.hstack([mob_te_reshape, Demo_val_te])\n",
        "\n",
        "    Covar_tr_mean = np.mean(Covar_tr, axis=0)\n",
        "    Covar_tr_std = np.std(Covar_tr, axis=0)\n",
        "\n",
        "    Covar_tr = (Covar_tr - Covar_tr_mean) / Covar_tr_std\n",
        "    Covar_te = (Covar_te - Covar_tr_mean) / Covar_tr_std\n",
        "\n",
        "    # Get Variable names\n",
        "    #clean up variable names\n",
        "    VarNamesOld = np.concatenate([Mobi_Type_list, Demo_Type_list.T, ['Qprob']])\n",
        "    VarNames = [name.replace(' & ', '_').replace(' ', '_').lstrip('_') for name in VarNamesOld]\n",
        "\n",
        "    # Define Parameters\n",
        "    n_day_tr = n_day\n",
        "    T = n_day_tr\n",
        "    dry_correct = 14\n",
        "\n",
        "    emiter = EMitr\n",
        "    break_diff = 1e-3\n",
        "    day_for_tr = min(T - dry_correct, mob_tr.shape[1])\n",
        "\n",
        "    # Initialize Inferred Parameters\n",
        "    if (alphaScale_in == 0) and (betaShape_in == 0):\n",
        "        alpha = 2\n",
        "        beta = 2\n",
        "    else:\n",
        "        alpha = alphaScale_in\n",
        "        beta = betaShape_in\n",
        "\n",
        "    # Initial Weibull values\n",
        "    wbl_val = np.tile(np.tril(weibull_min.pdf(np.arange(1, n_day_tr+1)[:,None] - np.arange(1, n_day_tr+1), c=beta, loc=0, scale=alpha)), (n_cty, 1))\n",
        "    print(f'shape of wbl_val: {wbl_val.shape})')\n",
        "\n",
        "    # K0 reproduction number, a function of time and mobility.\n",
        "    # K0 is a n_county * n_day by n_day matrix.\n",
        "    K0 = np.ones((n_cty, n_day_tr))\n",
        "    print(f'shape of K0(reproductive number): {K0.shape})')\n",
        "    K0_ext_j = np.repeat(K0, n_day_tr, axis=0)\n",
        "    print(f'shape of K0_ext_j(adjusted): {K0_ext_j.shape})')\n",
        "\n",
        "    # q is a n_county * n_day by n_day matrix.\n",
        "    q = sparse.lil_matrix((n_cty * n_day_tr, n_day_tr))\n",
        "\n",
        "    # Mu is the background rate\n",
        "    mus = 0.5 * np.ones(n_cty)\n",
        "    mus = mus.reshape(n_cty , 1)\n",
        "    print(f'mus shape is: {mus.shape}')\n",
        "\n",
        "    # lam is the event intensity\n",
        "    lam = np.zeros((n_cty, T))\n",
        "\n",
        "    # EM iteration\n",
        "    alpha_delta = []\n",
        "    alpha_prev = []\n",
        "    beta_delta = []\n",
        "    beta_prev = []\n",
        "    mus_delta = []\n",
        "    mus_prev = []\n",
        "    K0_delta = []\n",
        "    K0_prev = []\n",
        "    theta_delta = []\n",
        "    theta_prev = []\n",
        "\n",
        "    for itr in range(emiter):\n",
        "        start_time = time.time()\n",
        "\n",
        "        # E-step\n",
        "        q = K0_ext_j * wbl_val * (covid_tr_ext_j(covid_tr, n_day_tr) > 0)\n",
        "        print(f'shape of q: {q.shape}')\n",
        "        print(f'shape of covid_tr: {covid_tr_ext_j(covid_tr, n_day_tr).shape}')\n",
        "\n",
        "        eye_mu_1 = sparse.eye(n_day_tr)\n",
        "        dense_eye_1 = eye_mu_1.todense()\n",
        "        eye_mu_1 = np.tile(dense_eye_1, (n_cty, 1))\n",
        "        eye_mu_2 = np.tile(mus,(n_day_tr,1))\n",
        "        eye_mu = eye_mu_1 * eye_mu_2\n",
        "        eye_mu = np.kron(sparse.eye(n_day_tr), np.ones((n_cty, 1))) * np.tile(mus,(n_day_tr,1))\n",
        "        #eye_mu = eye_mu.toarray()\n",
        "        print(f'shape of eye_mu (should be (470,47)): {eye_mu.shape}')\n",
        "\n",
        "        print(f'shape of q * covid_tr_ext_j(covid_tr, n_day_tr): {q * covid_tr_ext_j(covid_tr, n_day_tr).shape} ')\n",
        "        lam = np.sum(q * covid_tr_ext_j(covid_tr, n_day_tr) + eye_mu, axis=1)\n",
        "        lam_eq_zero = lam == 0\n",
        "\n",
        "        q /= lam\n",
        "        q[lam_eq_zero, :] = 0\n",
        "\n",
        "        lam = lam.reshape(n_day_tr, n_cty).T\n",
        "\n",
        "        # Prepare data for Poisson regression\n",
        "        X = Covar_tr[:n_cty*day_for_tr, :]\n",
        "        y = Q[:, :day_for_tr].flatten()\n",
        "        weights = covid_tr[:, :day_for_tr].flatten()\n",
        "        # Fit Poisson regression model\n",
        "        model = LinearRegression().fit(X, y, sample_weight=weights)\n",
        "        # Predict and reshape\n",
        "        ypred = model.predict(Covar_tr)\n",
        "        K0 = ypred.reshape(n_cty, n_day_tr)\n",
        "\n",
        "        # M-step\n",
        "        Q = np.reshape(q * covid_tr_ext_i[:, :n_day_tr, :], (n_day_tr, n_day_tr * n_cty))\n",
        "        Q = np.reshape(np.sum(Q, axis=1), (n_cty, n_day_tr))\n",
        "\n",
        "        # Parameters for Poisson regression\n",
        "        glm_tr = Covar_tr[:n_cty*day_for_tr, :]\n",
        "        glm_y = Q[:, :day_for_tr].flatten()\n",
        "\n",
        "        design_matrix = sm.add_constant(glm_tr)\n",
        "\n",
        "        family = Poisson()\n",
        "        model = sm.GLM(glm_y, design_matrix, family=family, extra_kwds={'weights': freqs.flatten()})\n",
        "        result = model.fit()\n",
        "        print(model)\n",
        "\n",
        "        ypred, yci = result.predict(sm.add_constant(Covar_tr))\n",
        "\n",
        "        # Reshape ypred to match the original dimensions\n",
        "        K0 = np.reshape(ypred, (n_cty, n_day_tr))\n",
        "\n",
        "        # Bound K0\n",
        "        K0 = savgol_filter(K0, window_length=5, polyorder=2)  # Adjust window_length and polyorder as needed\n",
        "\n",
        "        # Repeat K0_smoothed to match the required shape\n",
        "        K0_ext_j = np.repeat(K0, n_day_tr, axis=0)\n",
        "\n",
        "        lam_eq_zero = np.where(lam[:, :day_for_tr] == 0)[0]\n",
        "        mus[lam != 0] /= lam[lam != 0, :day_for_tr]\n",
        "        mus[lam_eq_zero] = 0\n",
        "        # Calculate the average of mus weighted by covid_tr\n",
        "        mus_avg = np.sum(mus * covid_tr[:, :day_for_tr], axis=1) / day_for_tr\n",
        "\n",
        "         # Weibull fitting\n",
        "        if alphaScale_in == 0 and betaShape_in == 0:\n",
        "            obs = np.tril(np.arange(day_for_tr)**2)\n",
        "            freq = covid_tr_ext_j[covid_tr, n_day_tr] * covid_tr_ext_i[covid_tr, n_day_tr, n_cty] * q\n",
        "            freq = np.sum(freq, axis=-1)\n",
        "            obs = obs[freq > 0]\n",
        "            freq = freq[obs > 0]\n",
        "\n",
        "            popt, _ = curve_fit(stats.weibull_min.pdf, obs, freq, maxfev=500)\n",
        "            alpha, beta = popt\n",
        "\n",
        "            if beta > 100:\n",
        "                beta = 100\n",
        "            if alpha > 100:\n",
        "                alpha = 100\n",
        "        else:\n",
        "            alpha = alphaScale_in\n",
        "            beta = betaShape_in\n",
        "\n",
        "        # Convergence check\n",
        "        if itr == 1:\n",
        "            #save the first value\n",
        "            alpha_prev = alpha\n",
        "            beta_prev = beta\n",
        "            mus_prev = mus\n",
        "            K0_prev = K0.flatten()\n",
        "            theta_prev = model.coef_\n",
        "        else:\n",
        "            #calculate the RMSR\n",
        "            alpha_delta = np.sqrt((alpha - alpha_prev)**2)\n",
        "            beta_delta = np.sqrt((beta - beta_prev)**2)\n",
        "            mus_delta = np.sqrt(np.mean((mus_prev - mus)**2))\n",
        "            K0_delta = np.sqrt(np.mean((K0_prev - K0)**2))\n",
        "            theta_delta = np.sqrt(np.mean((theta_prev - model.coef_)**2))\n",
        "\n",
        "            #save the current\n",
        "            alpha_prev = alpha\n",
        "            beta_prev = beta\n",
        "            mus_prev = mus\n",
        "            K0_prev = K0.flatten()\n",
        "            theta_prev = model.coef_\n",
        "\n",
        "        # Check for convergence\n",
        "        if itr > 5:\n",
        "            if all(delta < break_diff for delta in [alpha_delta[-4:], beta_delta[-4:], mus_delta, K0_delta]):\n",
        "                print(\"Convergence Criterion Met. Breaking out of EM iteration...\")\n",
        "                break\n",
        "\n",
        "        elapsed_time = time.time() - start_time\n",
        "        print(f\"Iteration {itr+1}, Elapsed time: {elapsed_time:.2f} seconds\")\n",
        "\n",
        "        if itr == emiter - 1:\n",
        "            print('Reached maximum EM iteration.')\n",
        "\n",
        "\n",
        "    # Start Simulation\n",
        "    np.savez(OutputPath_mdl, mus=mus, alpha=alpha, beta=beta, K0=K0, VarNames=VarNames, alpha_delta=alpha_delta, beta_delta=beta_delta, mus_delta=mus_delta, K0_delta=K0_delta, theta_delta=theta_delta)\n",
        "    loaded_data = np.load(OutputPath_mdl + '.npz')\n",
        "\n",
        "    # Get K0\n",
        "    Covar_all = np.vstack((Covar_tr, Covar_te))\n",
        "    n_day = n_day_tr + DaysPred\n",
        "    T_sim = n_day\n",
        "    Tlow = T_sim - DaysPred\n",
        "\n",
        "    # Predict\n",
        "    ypred = model.predict(Covar_all)\n",
        "    fK0 = ypred.reshape(n_cty, n_day)\n",
        "\n",
        "    # Make fK0 stable\n",
        "    fK0[fK0 > 4] = 4\n",
        "\n",
        "    # Simulation results\n",
        "    sim = np.zeros((n_cty, T_sim, SimTimes))\n",
        "\n",
        "    # Simulate offsprings\n",
        "    n_per_batch = 10**2\n",
        "    K0_sim = fK0[:, Tlow:]\n",
        "\n",
        "    for itr in range(SimTimes):\n",
        "        np.random.seed(itr)\n",
        "\n",
        "        # Calculate base rate\n",
        "        base = np.zeros((n_cty, DaysPred))\n",
        "        n_exh = np.zeros((n_cty, DaysPred))\n",
        "\n",
        "        t_stamps = np.arange(Tlow + 1, T_sim + 1)[:, None] - np.arange(1, Tlow + 1)\n",
        "        intense = (weibull_min.pdf(t_stamps, alpha, scale=beta)[:, :, None] *\n",
        "                  fK0[:, :Tlow][:, None, :] *\n",
        "                  covid_tr[:, :Tlow][:, None, :])\n",
        "        base = np.sum(intense, axis=2) + mus\n",
        "        n_exh = np.random.poisson(base)\n",
        "\n",
        "        for itr_cty in range(int(np.ceil(n_cty * 0.5))):\n",
        "            for itr_d in range(DaysPred):\n",
        "                max_d = DaysPred - itr_d\n",
        "\n",
        "                # Sample first\n",
        "                if n_exh[itr_cty, itr_d] > n_per_batch:\n",
        "                    n_batch = n_exh[itr_cty, itr_d] // n_per_batch\n",
        "                    cand = np.random.poisson(K0_sim[itr_cty, itr_d], size=n_per_batch)\n",
        "                    n_mod = n_exh[itr_cty, itr_d] % n_per_batch\n",
        "                    n_offs = np.sum(cand) * n_batch + np.sum(np.random.poisson(K0_sim[itr_cty, itr_d], size=n_mod))\n",
        "                else:\n",
        "                    n_offs = np.sum(np.random.poisson(K0_sim[itr_cty, itr_d], size=n_exh[itr_cty, itr_d]))\n",
        "\n",
        "                if n_offs > n_per_batch:\n",
        "                    n_batch = n_offs // n_per_batch\n",
        "                    n_mod = n_offs % n_per_batch\n",
        "\n",
        "                    sim_cand_wbl = np.ceil(weibull_min.rvs(alpha, scale=beta, size=n_per_batch))\n",
        "                    sim_cand_wbl = sim_cand_wbl[sim_cand_wbl <= max_d]\n",
        "                    sim_cand_wbl = np.histogram(sim_cand_wbl, bins=np.arange(1, max_d + 2))[0]\n",
        "\n",
        "                    t_delta = np.ceil(weibull_min.rvs(alpha, scale=beta, size=n_mod))\n",
        "                    t_delta = t_delta[t_delta <= max_d]\n",
        "                    nt = np.histogram(t_delta, bins=np.arange(1, max_d + 2))[0] + sim_cand_wbl * n_batch\n",
        "                else:\n",
        "                    t_delta = np.ceil(weibull_min.rvs(alpha, scale=beta, size=n_offs))\n",
        "                    t_delta = t_delta[t_delta <= max_d]\n",
        "                    nt = np.histogram(t_delta, bins=np.arange(1, max_d + 2))[0]\n",
        "\n",
        "                n_exh[itr_cty, itr_d + 1:] += nt\n",
        "\n",
        "        sim[:, :, itr] = np.concatenate((covid_tr, n_exh[:, None]), axis=1)\n",
        "\n",
        "    sim_out = sim[:, -DaysPred:, :]\n",
        "\n",
        "    # Format the output\n",
        "    sim_mean = np.mean(sim_out, axis=2)\n",
        "    Date_pred = pd.date_range(start=NYT_Date_list[-1], periods=DaysPred, freq='D').strftime('%Y_%m_%d').to_list()\n",
        "    table_out = pd.DataFrame(sim_mean, columns=Date_pred)\n",
        "    table_out = pd.concat([NYT.iloc[:, :3], table_out], axis=1)\n",
        "\n",
        "    table_out.to_csv(OutputPath_pred, index=False)\n",
        "\n",
        "def covid_tr_ext_j(covid_tr, n_day_tr):\n",
        "    return np.repeat(covid_tr, n_day_tr, axis=0)\n",
        "\n",
        "def covid_tr_ext_i(covid_tr, n_day_tr, n_cty):\n",
        "    return np.tile(covid_tr.T, (1, n_day_tr)).T"
      ],
      "metadata": {
        "id": "oq8zKYsAaCDz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to your CSV file in Google Drive\n",
        "InputPath_demography = '/content/drive/My Drive/HawkPR_data_sim/Demo_Dconfirmed.csv'\n",
        "InputPath_report = '/content/drive/My Drive/HawkPR_data_sim/NYT_Dconfirmed.csv'\n",
        "InputPath_mobility = '/content/drive/My Drive/HawkPR_data_sim/GoogleMobi_Dconfirmed.csv'\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv(InputPath_demography)\n",
        "\n",
        "print(df.head())\n",
        "num_rows, num_columns = df.shape\n",
        "print(f'Number of rows: {num_rows}')\n",
        "print(f'Number of columns: {num_columns}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KI0U-QcoH8vS",
        "outputId": "81669b7d-059d-43c3-882e-3f9b6d48de5e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   countyFIPS  PopulationDensityperSqMile2010  PopulationEstimate2018  \\\n",
            "0        6037                          2419.6              10105518.0   \n",
            "1       17031                          5495.1               5180493.0   \n",
            "2       12086                          1315.5               2761581.0   \n",
            "3        4013                           414.9               4410824.0   \n",
            "4       48201                          2402.4               4698619.0   \n",
            "\n",
            "   #ICU_beds  MedianAge2010  Smokers_Percentage  DiabetesPercentage  \\\n",
            "0     2126.0           34.8           10.847678                 8.1   \n",
            "1     1606.0           35.3           13.776183                 9.0   \n",
            "2      593.0           38.2           16.479410                 6.7   \n",
            "3     1004.0           34.6           13.686398                 8.2   \n",
            "4      918.0           32.2           13.852122                10.3   \n",
            "\n",
            "   HeartDiseaseMortality  #Hospitals  \n",
            "0                  150.8        76.0  \n",
            "1                  175.1        46.0  \n",
            "2                  152.4        17.0  \n",
            "3                  130.3        34.0  \n",
            "4                  163.0        34.0  \n",
            "Number of rows: 2824\n",
            "Number of columns: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#scale of weibull\n",
        "Alpha = 4\n",
        "#shape of weibull\n",
        "Beta = 2\n",
        "\n",
        "# num of maximum iterations for EM algortihm in case convergence not reached\n",
        "EMitr = 20\n",
        "\n",
        "#additional days to be predicted by trained hawks process model\n",
        "DaysPred = 6\n",
        "\n",
        "#mobility shift parameter: ???\n",
        "Delta = 3\n",
        "\n",
        "SimTimes = 6\n",
        "\n",
        "#to_csv function will automatically create a csv file with this path\n",
        "OutputPath_pred = '/content/drive/My Drive/HawkPR_data_sim/Output.csv'\n",
        "OutputPath_mdl = '/content/drive/My Drive/HawkPR_data_sim/Output_mdl'"
      ],
      "metadata": {
        "id": "GkhREdRIP5WI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HawkPR(InputPath_report, InputPath_mobility, InputPath_demography, Delta, Alpha, Beta, EMitr, DaysPred, SimTimes, OutputPath_mdl, OutputPath_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "id": "DPr25HesaLKr",
        "outputId": "e1c91649-f0ab-4c58-d7b0-18d63c81ebf9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 10 counties, 6 types of Mobility indices, and 47 days in the COVID reports.\n",
            "shape of wbl_val: (470, 47))\n",
            "shape of K0(reproductive number): (10, 47))\n",
            "shape of K0_ext_j(adjusted): (470, 47))\n",
            "mus shape is: (10, 1)\n",
            "shape of q: (470, 47)\n",
            "shape of covid_tr: (470, 47)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "shapes (470,47) and (470,1) not aligned: 47 (dim 1) != 470 (dim 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-5cec75f075d4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mHawkPR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputPath_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputPath_mobility\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputPath_demography\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAlpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEMitr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDaysPred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSimTimes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutputPath_mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutputPath_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-d37610d3665d>\u001b[0m in \u001b[0;36mHawkPR\u001b[0;34m(InputPath_report, InputPath_mobility, InputPath_demography, Delta, Alpha, Beta, EMitr, DaysPred, SimTimes, OutputPath_mdl, OutputPath_pred)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0meye_mu_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense_eye_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_cty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0meye_mu_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_day_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0meye_mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meye_mu_1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0meye_mu_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0meye_mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_day_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_cty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_day_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;31m#eye_mu = eye_mu.toarray()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/matrixlib/defmatrix.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;31m# This promotes 1-D vectors to row vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__rmul__'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (470,47) and (470,1) not aligned: 47 (dim 1) != 470 (dim 0)"
          ]
        }
      ]
    }
  ]
}